{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MINIST\n",
    "import torch\n",
    "from mmcls.apis import init_model, show_result_pyplot\n",
    "import mmcv\n",
    "\n",
    "mnist_config = \"config/MINST_LeNet5.py\"\n",
    "imagenet_config = \"config/ImageNet_ResNet50.py\"\n",
    "checkpoint_file = \"/home/akiyo/nfs/zhang/pretrained_weights/resnet50_8xb256-rsb-a1-600e_in1k_20211228-20e21305.pth\"\n",
    "checkpoint_file = None\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = init_model(mnist_config, checkpoint_file, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(mmcls.models.classifiers.image.ImageClassifier,\n",
       " mmcls.models.classifiers.base.BaseClassifier,\n",
       " mmcv.runner.base_module.BaseModule,\n",
       " torch.nn.modules.module.Module,\n",
       " object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看模型继承结构/The model's inheritance relationship\n",
    "model.__class__.__mro__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 19:00:55,715 - mmcls - INFO - load checkpoint from local path: /home/akiyo/sandbox/work_dirs/MINST/latest.pth\n",
      "2022-12-10 19:00:55,721 - mmcls - INFO - Start running, host: akiyo@vali-docker, work_dir: /home/akiyo/sandbox/work_dirs/MINST\n",
      "2022-12-10 19:00:55,723 - mmcls - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-12-10 19:00:55,724 - mmcls - INFO - workflow: [('train', 1)], max: 5 epochs\n",
      "2022-12-10 19:00:55,725 - mmcls - INFO - Checkpoints will be saved to /home/akiyo/sandbox/work_dirs/MINST by HardDiskBackend.\n",
      "Exception ignored in: <function _releaseLock at 0x7ffbbb9bae50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/akiyo/miniconda3/envs/swint_new/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1363, in _pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1664, in _pydevd_bundle.pydevd_cython.ThreadTracer.__call__\n",
      "  File \"/home/akiyo/miniconda3/envs/swint_new/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_is_thread_alive.py\", line 9, in is_thread_alive\n",
      "    def is_thread_alive(t):\n",
      "KeyboardInterrupt: \n",
      "2022-12-10 19:00:59,854 - mmcls - INFO - Epoch [1][150/469]\tlr: 1.000e-02, eta: 0:00:59, time: 0.027, data_time: 0.018, memory: 707, loss: 0.0150\n",
      "2022-12-10 19:01:01,299 - mmcls - INFO - Epoch [1][300/469]\tlr: 1.000e-02, eta: 0:00:37, time: 0.010, data_time: 0.002, memory: 707, loss: 0.0220\n",
      "2022-12-10 19:01:02,931 - mmcls - INFO - Epoch [1][450/469]\tlr: 1.000e-02, eta: 0:00:30, time: 0.011, data_time: 0.002, memory: 707, loss: 0.0185\n",
      "2022-12-10 19:01:03,222 - mmcls - INFO - Saving checkpoint at 1 epochs\n",
      "2022-12-10 19:01:06,955 - mmcls - INFO - Epoch [2][150/469]\tlr: 1.000e-02, eta: 0:00:29, time: 0.024, data_time: 0.016, memory: 707, loss: 0.0164\n",
      "2022-12-10 19:01:08,490 - mmcls - INFO - Epoch [2][300/469]\tlr: 1.000e-02, eta: 0:00:25, time: 0.010, data_time: 0.002, memory: 707, loss: 0.0178\n",
      "2022-12-10 19:01:10,055 - mmcls - INFO - Epoch [2][450/469]\tlr: 1.000e-02, eta: 0:00:21, time: 0.010, data_time: 0.002, memory: 707, loss: 0.0185\n",
      "2022-12-10 19:01:10,295 - mmcls - INFO - Saving checkpoint at 2 epochs\n",
      "2022-12-10 19:01:13,947 - mmcls - INFO - Epoch [3][150/469]\tlr: 1.000e-02, eta: 0:00:20, time: 0.023, data_time: 0.015, memory: 707, loss: 0.0176\n",
      "2022-12-10 19:01:15,512 - mmcls - INFO - Epoch [3][300/469]\tlr: 1.000e-02, eta: 0:00:16, time: 0.010, data_time: 0.002, memory: 707, loss: 0.0167\n",
      "2022-12-10 19:01:16,988 - mmcls - INFO - Epoch [3][450/469]\tlr: 1.000e-02, eta: 0:00:14, time: 0.010, data_time: 0.002, memory: 707, loss: 0.0166\n",
      "2022-12-10 19:01:17,228 - mmcls - INFO - Saving checkpoint at 3 epochs\n",
      "2022-12-10 19:01:20,816 - mmcls - INFO - Epoch [4][150/469]\tlr: 1.000e-02, eta: 0:00:12, time: 0.023, data_time: 0.016, memory: 707, loss: 0.0151\n",
      "2022-12-10 19:01:22,392 - mmcls - INFO - Epoch [4][300/469]\tlr: 1.000e-02, eta: 0:00:09, time: 0.010, data_time: 0.002, memory: 707, loss: 0.0171\n",
      "2022-12-10 19:01:23,911 - mmcls - INFO - Epoch [4][450/469]\tlr: 1.000e-02, eta: 0:00:07, time: 0.010, data_time: 0.002, memory: 707, loss: 0.0148\n",
      "2022-12-10 19:01:24,200 - mmcls - INFO - Saving checkpoint at 4 epochs\n",
      "2022-12-10 19:01:27,950 - mmcls - INFO - Epoch [5][150/469]\tlr: 1.000e-02, eta: 0:00:04, time: 0.024, data_time: 0.015, memory: 707, loss: 0.0146\n",
      "2022-12-10 19:01:29,363 - mmcls - INFO - Epoch [5][300/469]\tlr: 1.000e-02, eta: 0:00:02, time: 0.009, data_time: 0.002, memory: 707, loss: 0.0143\n",
      "2022-12-10 19:01:30,798 - mmcls - INFO - Epoch [5][450/469]\tlr: 1.000e-02, eta: 0:00:00, time: 0.010, data_time: 0.002, memory: 707, loss: 0.0147\n",
      "2022-12-10 19:01:31,060 - mmcls - INFO - Saving checkpoint at 5 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 10000/10000, 1155.0 task/s, elapsed: 9s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 19:01:39,846 - mmcls - INFO - Epoch(val) [5][79]\taccuracy_top-1: 99.1200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from mmcv import Config\n",
    "from mmcls.datasets import build_dataset\n",
    "from mmcls.models import build_classifier\n",
    "from mmcls.apis import train_model\n",
    "\n",
    "cfg = model.cfg\n",
    "\n",
    "# Build the classifier\n",
    "#model.init_weights()\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Add `CLASSES` attributes to help visualization\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Only support single GPU\n",
    "train_model(\n",
    "    model, datasets, cfg, distributed=False, validate=True,\n",
    "    timestamp=time.strftime('%Y%m%d_%H%M%S', time.localtime()), meta=dict()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /home/akiyo/sandbox/work_dirs/MINST/latest.pth\n",
      "ImageClassifier(\n",
      "  (backbone): LeNet5(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (1): Tanh()\n",
      "      (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (4): Tanh()\n",
      "      (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "      (7): Tanh()\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=84, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (head): ClsHead(\n",
      "    (compute_loss): CrossEntropyLoss()\n",
      "    (compute_accuracy): Accuracy()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [6, 1, 5, 5], expected input[1, 3, 32, 32] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m image \u001b[39m=\u001b[39m mmcv\u001b[39m.\u001b[39mimread(resnet_image, channel_order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbrg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m image \u001b[39m=\u001b[39m mmcv\u001b[39m.\u001b[39mimrescale(image, \u001b[39m0.25\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m result \u001b[39m=\u001b[39m inference_model(model, image)\n\u001b[1;32m     14\u001b[0m show_result_pyplot(model, image, result)\n",
      "File \u001b[0;32m/share/zhang/github/mmclassification/mmcls/apis/inference.py:85\u001b[0m, in \u001b[0;36minference_model\u001b[0;34m(model, img)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m# forward the model\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 85\u001b[0m     scores \u001b[39m=\u001b[39m model(return_loss\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m     86\u001b[0m     pred_score \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(scores, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     87\u001b[0m     pred_label \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(scores, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/swint_new/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/swint_new/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py:119\u001b[0m, in \u001b[0;36mauto_fp16.<locals>.auto_fp16_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m@auto_fp16 can only be used to decorate the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    117\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmethod of those classes \u001b[39m\u001b[39m{\u001b[39;00msupported_types\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mfp16_enabled\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfp16_enabled):\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m old_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    121\u001b[0m \u001b[39m# get the arg spec of the decorated method\u001b[39;00m\n\u001b[1;32m    122\u001b[0m args_info \u001b[39m=\u001b[39m getfullargspec(old_func)\n",
      "File \u001b[0;32m/share/zhang/github/mmclassification/mmcls/models/classifiers/base.py:85\u001b[0m, in \u001b[0;36mBaseClassifier.forward\u001b[0;34m(self, img, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_train(img, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_test(img, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/share/zhang/github/mmclassification/mmcls/models/classifiers/base.py:67\u001b[0m, in \u001b[0;36mBaseClassifier.forward_test\u001b[0;34m(self, imgs, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m must be a list, but got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(var)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(imgs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimple_test(imgs[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     68\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39maug_test has not been implemented\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/share/zhang/github/mmclassification/mmcls/models/classifiers/image.py:152\u001b[0m, in \u001b[0;36mImageClassifier.simple_test\u001b[0;34m(self, img, img_metas, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimple_test\u001b[39m(\u001b[39mself\u001b[39m, img, img_metas\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    151\u001b[0m     \u001b[39m\"\"\"Test without augmentation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_feat(img)\n\u001b[1;32m    154\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead, MultiLabelClsHead):\n\u001b[1;32m    155\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs, (\n\u001b[1;32m    156\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mPlease use `sigmoid` instead of `softmax` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    157\u001b[0m             \u001b[39m'\u001b[39m\u001b[39min multi-label tasks.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/share/zhang/github/mmclassification/mmcls/models/classifiers/image.py:111\u001b[0m, in \u001b[0;36mImageClassifier.extract_feat\u001b[0;34m(self, img, stage)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m\"\"\"Directly extract features from the specified stage.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39m    torch.Size([1, 3072])\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39massert\u001b[39;00m stage \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mbackbone\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mneck\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpre_logits\u001b[39m\u001b[39m'\u001b[39m], \\\n\u001b[1;32m    108\u001b[0m     (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInvalid output stage \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mstage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, please choose from \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbackbone\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    109\u001b[0m      \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mneck\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpre_logits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone(img)\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m stage \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbackbone\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/swint_new/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/share/zhang/github/mmclassification/mmcls/models/backbones/lenet.py:38\u001b[0m, in \u001b[0;36mLeNet5.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 38\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m     39\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     40\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(x\u001b[39m.\u001b[39msqueeze())\n",
      "File \u001b[0;32m~/miniconda3/envs/swint_new/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/swint_new/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/swint_new/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/swint_new/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/swint_new/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [6, 1, 5, 5], expected input[1, 3, 32, 32] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "from mmcls.apis import train_model, inference_model\n",
    "\n",
    "minist_image = \"/home/akiyo/nfs/zhang/dataset/image/10022.png\"\n",
    "resnet_image = \"/home/akiyo/nfs/zhang/dataset/image/bear.jpg\"\n",
    "\n",
    "model = init_model(mnist_config, checkpoint_file, device=device)\n",
    "checkpoint_file = model.cfg.load_from\n",
    "\n",
    "image = mmcv.imread(resnet_image, channel_order='brg')\n",
    "image = mmcv.imrescale(image, 0.25)\n",
    "\n",
    "result = inference_model(model, image)\n",
    "show_result_pyplot(model, image, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af1ef7c2422b98f0aa0eb8c8ba68e52bc5e98ee3d10707544ebeb5411de3d7d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
